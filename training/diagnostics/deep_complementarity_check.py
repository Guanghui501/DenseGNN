"""
æ·±åº¦è¯Šæ–­: æ£€æŸ¥å›¾-æ–‡æœ¬äº’è¡¥æ€§

åŸºäºä½ çš„ç»“æœ:
- Graph-only: 18.79 MAE
- Text-only: 25.58 MAE
- Multimodal: 20.06 MAE (æ¯”Graphå·®!)

è¿™ä¸ªè„šæœ¬ä¼šå›ç­”:
1. æ–‡æœ¬å’Œå›¾å­¦åˆ°çš„æ˜¯ç›¸åŒä¿¡æ¯è¿˜æ˜¯ä¸åŒä¿¡æ¯?
2. ç®€å•çº¿æ€§ç»„åˆèƒ½å¦æ‰“è´¥18.79?
3. é—®é¢˜æ˜¯èåˆæœºåˆ¶è¿˜æ˜¯æ•°æ®æœ¬èº«?
"""

import numpy as np
import tensorflow as tf
from scipy.stats import pearsonr
from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt


def diagnose_graph_text_complementarity(graph_emb, text_emb, labels,
                                        graph_baseline_mae=18.79,
                                        text_baseline_mae=25.58,
                                        multimodal_mae=20.06):
    """
    è¯Šæ–­å›¾-æ–‡æœ¬äº’è¡¥æ€§é—®é¢˜

    æ£€æŸ¥:
    1. é¢„æµ‹é‡å åº¦ (ä¸¤ä¸ªæ¨¡æ€æ˜¯å¦å­¦åˆ°ç›¸åŒä¸œè¥¿)
    2. ç®€å•çº¿æ€§ç»„åˆæ€§èƒ½ (ç†è®ºä¸Šé™)
    3. è´Ÿå‘è¿ç§»æ£€æµ‹
    """

    print("\n" + "="*80)
    print("å›¾-æ–‡æœ¬äº’è¡¥æ€§æ·±åº¦è¯Šæ–­")
    print("="*80)

    # ç¡®ä¿æ˜¯numpy
    if tf.is_tensor(graph_emb):
        graph_emb = graph_emb.numpy()
    if tf.is_tensor(text_emb):
        text_emb = text_emb.numpy()
    if tf.is_tensor(labels):
        labels = labels.numpy()

    if len(labels.shape) > 1:
        labels = labels.flatten()

    # åˆ†å‰²æ•°æ®
    n = len(labels)
    train_idx = int(0.8 * n)

    g_train, g_val = graph_emb[:train_idx], graph_emb[train_idx:]
    t_train, t_val = text_emb[:train_idx], text_emb[train_idx:]
    y_train, y_val = labels[:train_idx], labels[train_idx:]

    results = {}

    # ========================================================================
    # æµ‹è¯•1: é¢„æµ‹é‡å åº¦æ£€æµ‹
    # ========================================================================
    print("\n[æµ‹è¯•1] é¢„æµ‹é‡å åº¦æ£€æµ‹")
    print("-" * 80)

    # è®­ç»ƒå•ç‹¬çš„å›¾æ¨¡å‹
    model_g = Ridge(alpha=1.0)
    model_g.fit(g_train, y_train)
    pred_g = model_g.predict(graph_emb)

    # è®­ç»ƒå•ç‹¬çš„æ–‡æœ¬æ¨¡å‹
    model_t = Ridge(alpha=1.0)
    model_t.fit(t_train, y_train)
    pred_t = model_t.predict(text_emb)

    # è®¡ç®—é¢„æµ‹çš„ç›¸å…³æ€§
    corr, p_value = pearsonr(pred_g, pred_t)

    print(f"å›¾é¢„æµ‹ vs æ–‡æœ¬é¢„æµ‹ ç›¸å…³æ€§: {corr:.3f}")

    results['prediction_correlation'] = float(corr)

    if corr > 0.8:
        print("\nğŸ”´ é—®é¢˜æ£€æµ‹: é«˜åº¦é‡å  (correlation > 0.8)")
        print("   â†’ æ–‡æœ¬å’Œå›¾å­¦åˆ°çš„æ˜¯**ç›¸åŒçš„ä¿¡æ¯**")
        print("   â†’ æ–‡æœ¬æ²¡æœ‰æä¾›æ–°çš„è¡¥å……ä¿¡æ¯")
        print("   â†’ å»ºè®®: **ä½¿ç”¨çº¯å›¾æ¨¡å‹** (18.79 MAE)")
        results['diagnosis'] = 'high_overlap'

    elif corr > 0.5:
        print("\nâš ï¸  ä¸­åº¦é‡å  (0.5 < correlation < 0.8)")
        print("   â†’ æ–‡æœ¬å’Œå›¾æœ‰éƒ¨åˆ†é‡å ï¼Œä½†ä¹Ÿæœ‰ç‹¬ç‰¹ä¿¡æ¯")
        print("   â†’ å¤šæ¨¡æ€å¯èƒ½æœ‰å°å¹…æå‡")
        results['diagnosis'] = 'medium_overlap'

    else:
        print("\nâœ… ä½é‡å  (correlation < 0.5)")
        print("   â†’ æ–‡æœ¬å’Œå›¾å­¦åˆ°äº†ä¸åŒçš„ä¿¡æ¯")
        print("   â†’ ç†è®ºä¸Šå¤šæ¨¡æ€åº”è¯¥èƒ½æ˜¾è‘—æå‡")
        results['diagnosis'] = 'low_overlap'

    # ========================================================================
    # æµ‹è¯•2: ç®€å•çº¿æ€§ç»„åˆæ€§èƒ½ (ç†è®ºä¸Šé™)
    # ========================================================================
    print("\n[æµ‹è¯•2] ç®€å•çº¿æ€§ç»„åˆæ€§èƒ½æµ‹è¯•")
    print("-" * 80)

    # æ–¹æ³•A: Concatenate + Ridge
    combined_train = np.concatenate([g_train, t_train], axis=-1)
    combined_val = np.concatenate([g_val, t_val], axis=-1)

    model_concat = Ridge(alpha=1.0)
    model_concat.fit(combined_train, y_train)
    pred_concat = model_concat.predict(combined_val)
    mae_concat = mean_absolute_error(y_val, pred_concat)

    # æ–¹æ³•B: åŠ æƒå¹³å‡ (å­¦ä¹ æƒé‡)
    # å­¦ä¹ æœ€ä¼˜alpha: final_pred = alpha * pred_g + (1-alpha) * pred_t
    best_alpha = None
    best_mae = float('inf')

    pred_g_val = model_g.predict(g_val)
    pred_t_val = model_t.predict(t_val)

    for alpha in np.linspace(0, 1, 101):
        pred_weighted = alpha * pred_g_val + (1 - alpha) * pred_t_val
        mae = mean_absolute_error(y_val, pred_weighted)
        if mae < best_mae:
            best_mae = mae
            best_alpha = alpha

    mae_weighted = best_mae

    # æ–¹æ³•C: Stacking (å…ˆé¢„æµ‹ï¼Œå†ç»„åˆé¢„æµ‹)
    stacking_train = np.stack([model_g.predict(g_train), model_t.predict(t_train)], axis=1)
    stacking_val = np.stack([pred_g_val, pred_t_val], axis=1)

    model_stack = Ridge(alpha=1.0)
    model_stack.fit(stacking_train, y_train)
    pred_stack = model_stack.predict(stacking_val)
    mae_stack = mean_absolute_error(y_val, pred_stack)

    print(f"\nç®€å•ç»„åˆæ–¹æ³•æµ‹è¯•:")
    print(f"  æ–¹æ³•A - Concat + Ridge:     {mae_concat:.2f} MAE")
    print(f"  æ–¹æ³•B - åŠ æƒå¹³å‡ (Î±={best_alpha:.2f}): {mae_weighted:.2f} MAE")
    print(f"  æ–¹æ³•C - Stacking:            {mae_stack:.2f} MAE")

    print(f"\nä¸åŸºçº¿å¯¹æ¯”:")
    print(f"  Graph-only åŸºçº¿:             {graph_baseline_mae:.2f} MAE")
    print(f"  ä½ çš„Multimodal:              {multimodal_mae:.2f} MAE")

    best_simple_mae = min(mae_concat, mae_weighted, mae_stack)
    results['best_simple_combination'] = float(best_simple_mae)
    results['concat_mae'] = float(mae_concat)
    results['weighted_mae'] = float(mae_weighted)
    results['stacking_mae'] = float(mae_stack)
    results['optimal_alpha'] = float(best_alpha)

    # åˆ†æ
    if best_simple_mae < graph_baseline_mae:
        improvement = graph_baseline_mae - best_simple_mae
        print(f"\nâœ… ç®€å•ç»„åˆèƒ½æ‰“è´¥åŸºçº¿! (æå‡ {improvement:.2f} MAE)")
        print(f"   â†’ ç†è®ºä¸Šé™: {best_simple_mae:.2f} MAE")
        print(f"   â†’ ä½ çš„æ¨¡å‹: {multimodal_mae:.2f} MAE")
        print(f"   â†’ å·®è·: {multimodal_mae - best_simple_mae:.2f} MAE")
        print("\n   ğŸ”´ é—®é¢˜è¯Šæ–­: **èåˆæœºåˆ¶ä¸å½“**")
        print("      ç®€å•çš„çº¿æ€§ç»„åˆéƒ½æ¯”ä½ çš„ç¥ç»ç½‘ç»œèåˆå¥½!")
        print("      è¯´æ˜é—®é¢˜ä¸åœ¨æ•°æ®ï¼Œè€Œåœ¨èåˆæ–¹å¼ã€‚")
        results['can_improve'] = True
        results['problem'] = 'fusion_mechanism'

    else:
        gap = best_simple_mae - graph_baseline_mae
        print(f"\nâŒ ç®€å•ç»„åˆæ‰“ä¸è´¥åŸºçº¿ (å·® {gap:.2f} MAE)")
        print(f"   â†’ å³ä½¿æœ€ä¼˜ç»„åˆä¹Ÿåªèƒ½è¾¾åˆ°: {best_simple_mae:.2f} MAE")
        print(f"   â†’ GraphåŸºçº¿: {graph_baseline_mae:.2f} MAE")
        print("\n   ğŸ”´ é—®é¢˜è¯Šæ–­: **è´Ÿå‘è¿ç§»**")
        print("      æ–‡æœ¬ä¿¡æ¯ä¸å›¾ä¿¡æ¯å†²çªï¼ŒåŠ å…¥æ–‡æœ¬åè€Œå˜å·®ã€‚")
        print("      å³ä½¿ç”¨ç®€å•çº¿æ€§ç»„åˆä¹Ÿæ— æ³•æå‡ã€‚")
        results['can_improve'] = False
        results['problem'] = 'negative_transfer'

    # ========================================================================
    # æµ‹è¯•3: ç‰¹å¾é‡è¦æ€§åˆ†æ
    # ========================================================================
    print("\n[æµ‹è¯•3] ç‰¹å¾é‡è¦æ€§åˆ†æ")
    print("-" * 80)

    # ä½¿ç”¨Lassoçœ‹å“ªäº›ç‰¹å¾é‡è¦
    model_lasso = Lasso(alpha=0.1)
    model_lasso.fit(combined_train, y_train)

    graph_dim = g_train.shape[1]
    text_dim = t_train.shape[1]

    graph_coef = model_lasso.coef_[:graph_dim]
    text_coef = model_lasso.coef_[graph_dim:]

    graph_importance = np.sum(np.abs(graph_coef))
    text_importance = np.sum(np.abs(text_coef))
    total_importance = graph_importance + text_importance

    graph_ratio = graph_importance / (total_importance + 1e-8)
    text_ratio = text_importance / (total_importance + 1e-8)

    print(f"çº¿æ€§æ¨¡å‹ä¸­çš„ç‰¹å¾é‡è¦æ€§:")
    print(f"  å›¾ç‰¹å¾é‡è¦æ€§: {graph_ratio:.1%}")
    print(f"  æ–‡æœ¬ç‰¹å¾é‡è¦æ€§: {text_ratio:.1%}")

    results['graph_importance_ratio'] = float(graph_ratio)
    results['text_importance_ratio'] = float(text_ratio)

    if text_ratio < 0.1:
        print("\nâš ï¸  æ–‡æœ¬ç‰¹å¾å‡ ä¹ä¸é‡è¦ (<10%)")
        print("   â†’ çº¿æ€§æ¨¡å‹ä¸»è¦ä¾èµ–å›¾ç‰¹å¾")
        print("   â†’ æ–‡æœ¬å¯¹é¢„æµ‹çš„è´¡çŒ®å¾ˆå°")

    # ========================================================================
    # æµ‹è¯•4: æ®‹å·®åˆ†æ (æ–‡æœ¬èƒ½å¦é¢„æµ‹å›¾çš„é”™è¯¯?)
    # ========================================================================
    print("\n[æµ‹è¯•4] æ®‹å·®åˆ†æ - æ–‡æœ¬èƒ½å¦ä¿®æ­£å›¾çš„é”™è¯¯?")
    print("-" * 80)

    # å›¾æ¨¡å‹çš„æ®‹å·®
    graph_residuals = y_train - model_g.predict(g_train)

    # ç”¨æ–‡æœ¬é¢„æµ‹è¿™äº›æ®‹å·®
    model_residual = Ridge(alpha=1.0)
    model_residual.fit(t_train, graph_residuals)

    # åœ¨éªŒè¯é›†ä¸Šæµ‹è¯•
    pred_g_val = model_g.predict(g_val)
    residual_correction = model_residual.predict(t_val)
    pred_corrected = pred_g_val + residual_correction

    mae_corrected = mean_absolute_error(y_val, pred_corrected)
    mae_graph_val = mean_absolute_error(y_val, pred_g_val)

    print(f"å›¾æ¨¡å‹ MAE: {mae_graph_val:.2f}")
    print(f"å›¾+æ–‡æœ¬æ®‹å·®ä¿®æ­£ MAE: {mae_corrected:.2f}")

    results['residual_correction_mae'] = float(mae_corrected)

    if mae_corrected < mae_graph_val:
        improvement = mae_graph_val - mae_corrected
        print(f"\nâœ… æ–‡æœ¬èƒ½ä¿®æ­£å›¾çš„é”™è¯¯! (æå‡ {improvement:.2f} MAE)")
        print("   â†’ æ–‡æœ¬åŒ…å«å›¾æ²¡æœ‰çš„è¡¥å……ä¿¡æ¯")
        print("   â†’ åº”è¯¥ä½¿ç”¨æ®‹å·®èåˆæ–¹å¼")
        results['text_can_correct'] = True
    else:
        print(f"\nâŒ æ–‡æœ¬æ— æ³•ä¿®æ­£å›¾çš„é”™è¯¯")
        print("   â†’ æ–‡æœ¬ä¸åŒ…å«è¡¥å……ä¿¡æ¯")
        print("   â†’ æˆ–è€…æ–‡æœ¬çš„ä¿¡æ¯å·²ç»åœ¨å›¾ä¸­äº†")
        results['text_can_correct'] = False

    # ========================================================================
    # æœ€ç»ˆå»ºè®®
    # ========================================================================
    print("\n" + "="*80)
    print("è¯Šæ–­ç»“è®ºä¸å»ºè®®")
    print("="*80)

    if results['problem'] == 'negative_transfer':
        print("\nğŸ”´ è¯Šæ–­: **è´Ÿå‘è¿ç§»**")
        print("\nç°è±¡:")
        print(f"  - å³ä½¿æœ€ä¼˜çº¿æ€§ç»„åˆ ({best_simple_mae:.2f}) ä¹Ÿæ¯”å›¾åŸºçº¿å·®")
        print(f"  - è¯´æ˜æ–‡æœ¬å’Œå›¾çš„ä¿¡æ¯äº’ç›¸å†²çª")
        print("\n**å¼ºçƒˆå»ºè®®: ä½¿ç”¨çº¯å›¾æ¨¡å‹ (18.79 MAE)**")
        print("\nåŸå› :")
        print("  - æ–‡æœ¬è™½ç„¶å•ç‹¬èƒ½é¢„æµ‹ (25.58 MAE)")
        print("  - ä½†ä¸å›¾ç»„åˆæ—¶äº§ç”Ÿè´Ÿé¢æ•ˆæœ")
        print("  - å¯èƒ½çš„åŸå› :")
        print("    * æ–‡æœ¬æè¿°çš„æ˜¯å®è§‚å±æ€§ï¼Œå›¾æè¿°çš„æ˜¯å¾®è§‚ç»“æ„")
        print("    * ä¸¤ä¸ªæ¨¡æ€çš„ä¿¡æ¯ä¸ä¸€è‡´")
        print("    * æ–‡æœ¬æœ‰ç³»ç»Ÿæ€§åå·®æˆ–é”™è¯¯")

    elif results['problem'] == 'fusion_mechanism':
        print("\nğŸ”´ è¯Šæ–­: **èåˆæœºåˆ¶é—®é¢˜**")
        print("\nç°è±¡:")
        print(f"  - ç®€å•çº¿æ€§ç»„åˆèƒ½è¾¾åˆ°: {best_simple_mae:.2f} MAE < 18.79")
        print(f"  - ä½ çš„ç¥ç»ç½‘ç»œèåˆ: {multimodal_mae:.2f} MAE > 18.79")
        print(f"  - æ€§èƒ½å·®è·: {multimodal_mae - best_simple_mae:.2f} MAE")
        print("\n**å»ºè®®: ä¿®å¤èåˆæœºåˆ¶**")
        print("\nå…·ä½“è¡ŒåŠ¨:")

        print(f"\n1. å°è¯•ç®€å•çº¿æ€§èåˆ (æœ€ä¼˜Î±={best_alpha:.2f})")
        print("   å®ç°:")
        print(f"   fused = {best_alpha:.2f} * graph_emb + {1-best_alpha:.2f} * text_emb")

        if results.get('text_can_correct', False):
            print("\n2. ä½¿ç”¨æ®‹å·®èåˆ (æ¨è!)")
            print("   æ–‡æœ¬èƒ½ä¿®æ­£å›¾çš„é”™è¯¯ï¼Œåº”è¯¥ç”¨è¿™ç§æ–¹å¼:")
            print("   å®ç°:")
            print("   graph_pred = graph_head(graph_emb)")
            print("   text_correction = text_head(text_emb)")
            print("   final_pred = graph_pred + 0.3 * text_correction")

        print("\n3. æ£€æŸ¥å½“å‰çš„gateæƒé‡")
        print("   æ‰“å°ä½ æ¨¡å‹çš„gateå€¼ï¼Œçœ‹æ˜¯å¦åˆç†")
        print(f"   ç†è®ºæœ€ä¼˜å€¼åº”è¯¥æ¥è¿‘: {best_alpha:.2f}")

        print("\n4. ç¦ç”¨ä¸­æœŸèåˆ")
        print("   use_middle_fusion=False")
        print("   åªç”¨late fusionå¯èƒ½æ›´ç¨³å®š")

    # ä¿å­˜ç»“æœ
    import json
    with open('./complementarity_diagnosis.json', 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\nå®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: ./complementarity_diagnosis.json")
    print("="*80 + "\n")

    return results


def plot_predictions_comparison(graph_pred, text_pred, labels, save_path='./predictions_comparison.png'):
    """å¯è§†åŒ–å›¾å’Œæ–‡æœ¬çš„é¢„æµ‹å¯¹æ¯”"""

    fig, axes = plt.subplots(2, 2, figsize=(12, 10))

    # 1. Graph predictions vs labels
    ax = axes[0, 0]
    ax.scatter(labels, graph_pred, alpha=0.5, s=20)
    ax.plot([labels.min(), labels.max()], [labels.min(), labels.max()], 'r--', lw=2)
    ax.set_xlabel('True Labels')
    ax.set_ylabel('Graph Predictions')
    ax.set_title('Graph Predictions vs True Labels')
    ax.grid(True, alpha=0.3)

    # 2. Text predictions vs labels
    ax = axes[0, 1]
    ax.scatter(labels, text_pred, alpha=0.5, s=20)
    ax.plot([labels.min(), labels.max()], [labels.min(), labels.max()], 'r--', lw=2)
    ax.set_xlabel('True Labels')
    ax.set_ylabel('Text Predictions')
    ax.set_title('Text Predictions vs True Labels')
    ax.grid(True, alpha=0.3)

    # 3. Graph vs Text predictions
    ax = axes[1, 0]
    ax.scatter(graph_pred, text_pred, alpha=0.5, s=20)
    ax.set_xlabel('Graph Predictions')
    ax.set_ylabel('Text Predictions')
    ax.set_title('Graph vs Text Predictions\n(High correlation = high overlap)')
    ax.grid(True, alpha=0.3)

    # Add correlation
    from scipy.stats import pearsonr
    corr, _ = pearsonr(graph_pred, text_pred)
    ax.text(0.05, 0.95, f'Correlation: {corr:.3f}',
            transform=ax.transAxes, va='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    # 4. Residuals
    ax = axes[1, 1]
    graph_residuals = labels - graph_pred
    text_residuals = labels - text_pred
    ax.scatter(graph_residuals, text_residuals, alpha=0.5, s=20)
    ax.axhline(y=0, color='r', linestyle='--', lw=1)
    ax.axvline(x=0, color='r', linestyle='--', lw=1)
    ax.set_xlabel('Graph Residuals')
    ax.set_ylabel('Text Residuals')
    ax.set_title('Residuals Comparison\n(Quadrants show where each modality fails)')
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"é¢„æµ‹å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")
    plt.close()


if __name__ == '__main__':
    print("""
è¿™ä¸ªè„šæœ¬éœ€è¦ä½ æä¾›:
- graph_emb: å›¾åµŒå…¥
- text_emb: æ–‡æœ¬åµŒå…¥
- labels: çœŸå®æ ‡ç­¾

ä½¿ç”¨æ–¹æ³•:

from diagnostics.deep_complementarity_check import diagnose_graph_text_complementarity

# ä»ä½ çš„æ¨¡å‹æå–åµŒå…¥
graph_emb = model.get_layer('graph_projection').output  # æˆ–è€…å…¶ä»–æ–¹å¼æå–
text_emb = model.get_layer('text_projection').output

# è¿è¡Œè¯Šæ–­
results = diagnose_graph_text_complementarity(
    graph_emb=graph_emb,
    text_emb=text_emb,
    labels=labels,
    graph_baseline_mae=18.79,
    text_baseline_mae=25.58,
    multimodal_mae=20.06
)

# æŸ¥çœ‹ç»“æœ
print(results)
""")
